---
title: "Class 8: Breast Cancer Analysis Mini Project"
author: "Jiayi Zhou (PID:A17856751)"
format: pdf
toc: TRUE
---

## Background

The goal of this mini-project is to explore a complete analysis using the unsupervised learning techniques covered in our last class.

The data itself comes from the Wisconsin Breast Cancer Diagnostic Data Set first reported by K. P. Benne and O. L. Mangasarian: "Robust Linear Programming Discrimination of Two Linearly Inseparable Sets".

Values in this data set describe characteristics of the cell nuclei present in digitized images of a fine needle aspiration (FNA) of a breast mass.

## Data import

Data was downloaded from the class website as a CSV file.

```{r}
wisc.df <- read.csv("WisconsinCancer.csv", row.names=1)
head(wisc.df)
```

Remove the diagnosis from data for subsequent analysis
```{r}
wisc.data <- wisc.df[,-1]
dim(wisc.data)
```

The first column `diagnosis` is the expert opinion on the sample (i.e. patient FNA).

```{r}
head(wisc.df$diagnosis)
```

```{r}
head(wisc.df[,-1])
```

Remove the diagnosis from data for subsequent analysis
```{r}
wisc.data <- wisc.df[,-1]
dim(wisc.data)
```

Store the diagnosis as a vector for use lator when we compare our results to those from experts in the field.

```{r}
diagnosis <- factor(wisc.df$diagnosis)
```

## Data Exploration

> Q1. How many observations are in the dataset?

There are `r nrow(wisc.data)` obsrvations/pateinets in the dataset.

> Q2. How many of the observations have a malignant diagnosis?

```{r}
table(wisc.df$diagnosis)
```

212 samples are malignant (M).

> Q3. How many variables/features in the data are suffixed with _mean?

```{r}
#colnames(wisc.data)
length(grep("_mean", colnames(wisc.data)))
```

10 features end with _mean.

## Principal Component Analysis

The `prcomp()` function to do PCA has a `scale-FLASE` default. In general we nearly always want to set this to TRUE so our analysis is not dominated by columns/variables in our dataset that have high standard deviation and mean when compared to others just because the units of measurements are on different unit/scales.

```{r}
wisc.pr <- prcomp(wisc.data, scale=TRUE)
summary(wisc.pr)
```
> Q4. From your results, what proportion of the original variance is captured by the first principal components (PC1)?

PC1 Proportion of Variance = 0.4427, which is 44.27%. So 44.27% of the variance is captured by PC1.

> Q5. How many principal components (PCs) are required to describe at least 70% of the original variance in the data? 

After PC3 0.72636 (≥ 0.70), the first point that meets the target. So 3 PCs.

> Q6. How many principal components (PCs) are required to describe at least 90% of the original variance in the data?

After PC7 0.91010 (≥ 0.90), the first point that meets the target. So 7 PCs.

> Q7. What stands out to you about this plot? Is it easy or difficult to understand? Why?

The biplot is difficult to interpret because the rownames clutter the plot, making trends and groupings hard to see in this high-dimensional dataset.

### PCA Score Plot

The main PC result figure is called a "score plot" or "PC plot" or "ordination plot"...

```{r}
library(ggplot2)

ggplot(wisc.pr$x) +
  aes(PC1, PC2, col=diagnosis) +
  geom_point()
```

> Q8. Generate a similar plot for principal components 1 and 3. What do you notice about these plots?

```{r}
# Repeat for components 1 and 3
plot(wisc.pr$x[, c(1, 3)], col = diagnosis, xlab = "PC1", ylab = "PC3")
```
The PC1 vs PC3 plot shows less distinct separation between malignant and benign samples compared to PC1 vs PC2, because principal component 3 explains less variance than principal component 2, making the groupings less clear.

## PCA Scree Plot

```{r}
pr.var <- wisc.pr$sdev^2
head(pr.var)
```

```{r}
# Variance explained by each principal component: pve
pve <- pr.var / sum(pr.var)

# Plot variance explained for each principal component
plot(pve, xlab = "Principal Component",
     ylab = "Proportion of Variance Explained",
     ylim = c(0, 1), type = "o")
```

```{r}
barplot(pve, ylab = "Percent of Variance Explained",
        names.arg = paste0("PC", 1:length(pve)), las = 2, axes = FALSE)
axis(2, at = pve, labels = round(pve, 2) * 100)
```

There are quite a few CRAN packages that are helpful for PCA. This includes the factoextra package. Feel free to explore this package. For example:

```{r}
library(factoextra)
fviz_eig(wisc.pr, addlabels = TRUE)
```


### Communicating PCA results

> Q9. For the first principal component, what is the component of the loading vector (i.e. wisc.pr$rotation[,1]) for the feature concave.points_mean?

```{r}
wisc.pr$rotation["concave.points_mean","PC1"]
```

Loading of concave.points_mean on PC1 is −0.2608538.


> Q10. What is the minimum number of principal components required to explain 80% of the variance of the data?

We need 5 PCs to capture more than 80% variance.

```{r}
summary(wisc.pr)
```

## Hierarchical clustering

Just clustering the original data is not very informative or helpful.

```{r}
data.scaled <- scale(wisc.data)
data.dist <- dist(data.scaled)
wisc.hclust <- hclust(data.dist)
```

View the clustering dendrogram result

```{r}
plot(wisc.hclust)
```
```{r}
wisc.hclust.clusters <- cutree(wisc.hclust, k=4)
table(wisc.hclust.clusters)

```
```{r}
table(wisc.hclust.clusters, diagnosis)
```

## Combing methods (PCA and Clustering)

Clustering the origional data was not very productive. The PCA results looked promising. Here we combine these methods by clustering from our PCA results. In other words "clustering in PC space"...

> Q11. Using the plot() and abline() functions, what is the height at which the clustering model has 4 clusters?

```{r}
## Take the first 3 PCs
dist.pc <- dist(wisc.pr$x[,1:3])
wisc.pr.hclust <- hclust(dist.pc, method="ward.D2")
```

View the tree...
```{r}
N <- length(wisc.pr.hclust$height)
h_cut <- mean(wisc.pr.hclust$height[c(N-3, N-2)])

plot(wisc.pr.hclust)
abline(h = h_cut, col = "red", lty = 2)
```

> Q12. Can you find a better cluster vs diagnoses match by cutting into a different number of clusters between 2 and 10?

```{r}
for (k in 2:10) {
  cat("\n# k =", k, "\n")
  print(table(cutree(wisc.hclust, k), diagnosis))
  cat("Accuracy:",
      round(sum(apply(table(cutree(wisc.hclust, k), diagnosis), 1, max)) / length(diagnosis), 4),
      "\n")
}
```
The best match occurs at k = 9and k = 10.

>Q13. Which method gives your favorite results for the same data.dist dataset? Explain your reasoning.

The Ward.D2 method gives the best results because it minimizes the total within-cluster variance at each merging step, rather than focusing only on distances between points, leading to tighter groupings ideal for this dataset.

To get our clustering membership vector (i.e. our main clustering result) we "cut" the tree at a desired height or to yield a desired number of "k" groups.

```{r}
grps <- cutree(wisc.pr.hclust, k=2)
table(grps)
```

How does this clustering gps compare to the expert diagnosis

```{r}
table(grps, diagnosis)
```
```{r}
plot(wisc.pr$x[,1:2], col=grps)
plot(wisc.pr$x[,1:2], col=diagnosis)
```
> Q15. How well does the newly created model with four clusters separate out the two diagnoses?

```{r}
wisc.pr.hclust <- hclust(dist(wisc.pr$x[, 1:7]), method = "ward.D2")
wisc.pr.hclust.clusters <- cutree(wisc.pr.hclust, k = 2)
table(wisc.pr.hclust.clusters, diagnosis)
```

> Q16. How well do the k-means and hierarchical clustering models you created in previous sections (i.e. before PCA) do in terms of separating the diagnoses? Again, use the table() function to compare the output of each model (wisc.km$cluster and wisc.hclust.clusters) with the vector containing the actual diagnoses.

```{r}
set.seed(1234); wisc.km <- kmeans(scale(wisc.data), centers = 2, nstart = 20)
wisc.hclust.clusters <- cutree(wisc.hclust, k = 4)
table(wisc.km$cluster, diagnosis)
table(wisc.hclust.clusters, diagnosis)
```
Sensitivity: TP/(TP+FN)
Specificity: TN/(TN+FN)

> Q17. Which of your analysis procedures resulted in a clustering model with the best specificity? How about sensitivity?

Best specificity: k-means and hierarchical.
Best sensitivity: PCA and Ward.D2.


## 7. Prediction

We can use our PCA model for prediction with new input patient samples.

```{r}
#url <- "new_samples.csv"
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata=new)
npc
```

```{r}
g <- relevel(factor(grps), ref = "2")
plot(wisc.pr$x[,1:2], col=g)
points(npc[,1], npc[,2], col="blue", pch=16, cex=3)
text(npc[,1], npc[,2], c(1,2), col="white")
```

> Q18. Which of these new patients should we prioritize for follow up based on your results?

Prioritize New Patient 1 for follow-up.
Malignant cases sit at higher PC1 (larger, more irregular nuclei). Patient 1 has PC1 ≈ +2.58, while Patient 2 has PC1 ≈ −4.75.
